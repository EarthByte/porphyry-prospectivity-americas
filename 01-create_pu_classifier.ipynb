{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train positive-unlabelled (PU) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If training data has been extracted from the source datasets by running the `00a-extract_training_data.ipynb` and `00b-extract_grid_data.ipynb` notebooks, set the `use_extracted_data` variable below to `True` to use this dataset instead of the pre-prepared training data from the [Zenodo repository](https://zenodo.org/record/8157691)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_extracted_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore::FutureWarning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from pulearn.bagging import BaggingPuClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "from lib.check_files import check_prepared_data\n",
    "from lib.pu import (\n",
    "    BASE_MODELS,\n",
    "    PU_PARAMS,\n",
    "    downsample_unlabelled,\n",
    "    get_xy,\n",
    ")\n",
    "\n",
    "# Suppress FutureWarning for some versions of Scikit-learn\n",
    "%env PYTHONWARNINGS=ignore::FutureWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "random_seed = 1234\n",
    "\n",
    "# Number of jobs used to train model\n",
    "n_jobs = 4\n",
    "\n",
    "rf_params = {\"random_state\": random_seed}\n",
    "pu_params = {\n",
    "    \"n_jobs\": n_jobs,\n",
    "    \"random_state\": random_seed,\n",
    "    **PU_PARAMS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/output files\n",
    "if use_extracted_data:\n",
    "    data_dir = \"extracted_data\"\n",
    "else:\n",
    "    data_dir = \"prepared_data\"\n",
    "    check_prepared_data(data_dir, verbose=True)\n",
    "data_filename = os.path.join(data_dir, \"training_data.csv\")\n",
    "\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_filename = os.path.join(output_dir, \"pu_classifier.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region  label     \n",
      "NAm     positive      217\n",
      "        unlabelled    183\n",
      "SAm     positive      130\n",
      "        unlabelled    164\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_filename)\n",
    "\n",
    "# Drop negatively-labelled samples\n",
    "data = data[data[\"label\"] != \"negative\"]\n",
    "\n",
    "# Restrict unlabelled training data to the Americas\n",
    "data = data[data[\"region\"].isin({\"NAm\", \"SAm\"})]\n",
    "\n",
    "# Equal number of positive and unlabelled samples\n",
    "data_downsampled = downsample_unlabelled(\n",
    "    data,\n",
    "    random_state=random_seed,\n",
    ")\n",
    "\n",
    "print(data_downsampled.groupby([\"region\", \"label\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 25) (633,)\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant columns in NumPy array form\n",
    "x, y = get_xy(data_downsampled)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the PU classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base random forest model:\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': 1,\n",
      " 'oob_score': False,\n",
      " 'random_state': 1234,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Use a random forest as the base classifier\n",
    "base_model = clone(BASE_MODELS[\"randomforest\"])\n",
    "base_model.set_params(**rf_params)\n",
    "print(\"Base random forest model:\")\n",
    "pprint.pprint(base_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PU model:\n",
      "{'base_estimator': RandomForestClassifier(n_estimators=50, n_jobs=1, random_state=1234),\n",
      " 'base_estimator__bootstrap': True,\n",
      " 'base_estimator__ccp_alpha': 0.0,\n",
      " 'base_estimator__class_weight': None,\n",
      " 'base_estimator__criterion': 'gini',\n",
      " 'base_estimator__max_depth': None,\n",
      " 'base_estimator__max_features': 'sqrt',\n",
      " 'base_estimator__max_leaf_nodes': None,\n",
      " 'base_estimator__max_samples': None,\n",
      " 'base_estimator__min_impurity_decrease': 0.0,\n",
      " 'base_estimator__min_samples_leaf': 1,\n",
      " 'base_estimator__min_samples_split': 2,\n",
      " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
      " 'base_estimator__n_estimators': 50,\n",
      " 'base_estimator__n_jobs': 1,\n",
      " 'base_estimator__oob_score': False,\n",
      " 'base_estimator__random_state': 1234,\n",
      " 'base_estimator__verbose': 0,\n",
      " 'base_estimator__warm_start': False,\n",
      " 'bootstrap': True,\n",
      " 'bootstrap_features': False,\n",
      " 'max_features': 1.0,\n",
      " 'max_samples': 1.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': 4,\n",
      " 'oob_score': True,\n",
      " 'random_state': 1234,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Train the PU classifier\n",
    "pu_model = BaggingPuClassifier(base_estimator=base_model, **pu_params)\n",
    "print(\"PU model:\")\n",
    "pprint.pprint(pu_model.get_params())\n",
    "pu_model = pu_model.fit(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `joblib` to save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/pu_classifier.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pu_model, output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models for NA and SA only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: NAm\n",
      "region  label     \n",
      "NAm     positive      217\n",
      "        unlabelled    217\n",
      "dtype: int64\n",
      "\n",
      "Region: SAm\n",
      "region  label     \n",
      "SAm     positive      130\n",
      "        unlabelled    130\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_na = data[data[\"region\"] == \"NAm\"]\n",
    "for region, subset in data.groupby(\"region\"):\n",
    "    region = str(region)\n",
    "    print(f\"Region: {region}\")\n",
    "    output_subset = os.path.join(\n",
    "        output_dir,\n",
    "        f\"pu_classifier_{region[:2]}.joblib\",\n",
    "    )\n",
    "\n",
    "    subset = downsample_unlabelled(\n",
    "        subset,\n",
    "        random_state=random_seed,\n",
    "    )\n",
    "    print(subset.groupby([\"region\", \"label\"]).size())\n",
    "\n",
    "    x, y = get_xy(subset)\n",
    "    base_model = clone(BASE_MODELS[\"randomforest\"])\n",
    "    base_model.set_params(**rf_params)\n",
    "\n",
    "    pu_model = BaggingPuClassifier(base_estimator=base_model, **pu_params)\n",
    "    pu_model = pu_model.fit(x, y)\n",
    "    dump(pu_model, output_subset)\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
